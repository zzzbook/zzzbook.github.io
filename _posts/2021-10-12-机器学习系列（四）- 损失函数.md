---
layout: post
title: 机器学习系列（四）- 损失函数
date: 2021-10-12
categories: 机器学习系列
tags: 研究生 机器学习

---

# 机器学习系列（四）- 损失函数

- 视频参考：[“损失函数”是如何设计出来的？直观理解“最小二乘法”和“极大似然估计法”](https://www.bilibili.com/video/BV1Y64y1Q7hi)
- **损失函数可理解为神经网络的标准与人的标准，相差的定量表达**

## 基础概念

### 最小二乘法

<img src="http://r0umepz0y.hb-bkt.clouddn.com/img/image-20211012134020697.png" alt="image-20211012134020697" style="zoom:50%;" />

- **推导过程**
  1. 定义人对 $x_i$ 的判断结果 $X_i\in\{0,1\}$，神经网络的判断结果 $\widehat{y}_i\sim(0,1)$ 
  2. 则每张图片标准相差 $\left|X_i-\widehat{y}_i\right|$
  3. 将所有结果求和并取最小值 $min\sum_{i=1}^n\left|X_i-\widehat{y}_i\right|$ 
  4. 绝对值在定义域内不一定全程可导，通常改为 $$min\sum_{i=1}^n(X_i-\widehat{y}_i)^2$$ 

### 极大似然估计法

- 函数 $P(x|\theta)$ ，其中 $x$ 表示某一个具体数据； $\theta$ 表示模型的参数；
  1. 如果 $\theta$ 是已知确定的， $x$ 是变量，这个函数叫做概率函数，它描述对于不同的样本点 $x$ ，其出现概率是多少。
  2. 如果 $x$ 是已知确定的， $\theta$ 是变量，这个函数叫做似然函数，它描述对于不同模型参数，出现 $x$ 这个样本点的概率是多少。
- **推导过程**

  1. 定义模型参数 $W,b$ ，已知结果 $x_1,x_2,...,x_n$ ，模型结果 $y_1,y_2,...,y_n$ 
  
  2. 则定义公式 ${P}(x_1,x_2,...,x_n{\mid}W,b)=\prod_{i=1}^{n}P(x_i{\mid}W,b)$ 
  
  3. 因通过参数 $W,b$ 的模型得到的结果为 $y_n$ ，故公式转变为 $\prod_{i=1}^{n}P(x_i{\mid}y_i)$ 
  
  4. 其中 $x_n\in\{0,1\}$ 满足0-1分布 $f(x)=p^x(1-p)^{1-x}=\begin{cases}p,&x=1\\1-p,&x=0\end{cases}$ ，故转变为 $\prod_{i=1}^{n}y_i^{x_i}(1-y_i)^{1-x_i}$ 
  
  5. 将连乘转变为连加，前面增加 $log$ ，转变为
  
     $log(\prod_{i=1}^{n}y_i^{x_i}(1-y_i)^{1-x_i})=\sum_{i=1}^{n}log(y_i^{x_i}(1-y_i)^{1-x_i})=\sum_{i=1}^{n}(x_i·{log}y_i+(1-x_i)·log(1-y_i))$ 
  
  6. 求最大值，转变为最小值
  
     $max(\sum_{i=1}^{n}(x_i·{log}y_i+(1-x_i)·log(1-y_i)))=min-(\sum_{i=1}^{n}(x_i·{log}y_i+(1-x_i)·log(1-y_i)))$

### 交叉熵法



