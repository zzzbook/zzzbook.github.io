---
layout: post
title: 动手学深度学习v2-04 数据操作+数据预处理
date: 2021-12-28
categories: 动手学深度学习v2
tags: 研究生 深度学习

---

# 动手学深度学习v2-04 数据操作+数据预处理

- 视频参考：[04 数据操作 + 数据预处理【动手学深度学习v2】](https://www.bilibili.com/video/BV1CV411Y7i4?p=2)

## 基础数据操作

- 生成张量

  ```python
  import torch
  x = torch.arang(12)	# 顺序生成元素个数张量
  # tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])
  
  torch.zeros((2,3,4))	# 生成元素为 0 的多维张量
  # tensor([[[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]],
  #         [[0., 0., 0., 0.], [0., 0., 0., 0.], [0., 0., 0., 0.]]])
  
  torch.ones((2,3,4))	# 生成元素为 1 的多维张量
  # tensor([[[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]],
  #         [[1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 1., 1.]]])
  
  torch.tensor([[2,1,4,3],[1,2,3,4],[4,3,2,1]])	#生成自定义元素张量
  # tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])
  ```

- 张量基础操作

  - 获取每个维度大小：`x.shape`
  - 获取元素总个数：`x.numel()`
  - 元素求和：`x.sum()`
  - 多维度分组：`x.reshape(3,4)`

- 数据选择

  ```python
  X = torch.arange(12, dtype=torch.float32).reshape((3,4))
  X[:],	# 输出全部
  X[1:],	# 1行之后全部
  X[1: , 1:3],	# 1行之后全部,1-3列
  X[1: , 0::2]	# 1行之后全部,0列起每隔2列
  # (tensor([[ 0.,  1.,  2.,  3.], [ 4.,  5.,  6.,  7.], [ 8.,  9., 10., 11.]]),
  #  tensor([[ 4.,  5.,  6.,  7.], [ 8.,  9., 10., 11.]]),
  #  tensor([[ 5.,  6.], [ 9., 10.]]),
  #  tensor([[ 4.,  6.], [ 8., 10.]]))
  ```

- 张量维度合并

  ```python
  X = torch.arange(24, dtype=torch.float32).reshape((2,3,4))
  Y = torch.tensor([[[2,1,4,3],[1,2,3,4],[4,3,2,1]],[[2,1,4,3],[1,2,3,4],[4,3,2,1]]])
  torch.cat((X,Y), dim=0), torch.cat((X,Y), dim=1), torch.cat((X,Y), dim=2)	# 张量维度合并
  # (tensor([[[ 0.,  1.,  2.,  3.], [ 4.,  5.,  6.,  7.], [ 8.,  9., 10., 11.]],
  #          [[12., 13., 14., 15.], [16., 17., 18., 19.], [20., 21., 22., 23.]],
  #          [[ 2.,  1.,  4.,  3.], [ 1.,  2.,  3.,  4.], [ 4.,  3.,  2.,  1.]],
  #          [[ 2.,  1.,  4.,  3.], [ 1.,  2.,  3.,  4.], [ 4.,  3.,  2.,  1.]]]),
  # 
  #  tensor([[[ 0.,  1.,  2.,  3.], [ 4.,  5.,  6.,  7.], [ 8.,  9., 10., 11.], [ 2.,  1.,  4.,  3.], [ 1.,  2.,  3.,  4.], [ 4.,  3.,  2.,  1.]],
  #          [[12., 13., 14., 15.], [16., 17., 18., 19.], [20., 21., 22., 23.], [ 2.,  1.,  4.,  3.], [ 1.,  2.,  3.,  4.], [ 4.,  3.,  2.,  1.]]]),
  # 
  #  tensor([[[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.], [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.], [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]],
  #          [[12., 13., 14., 15.,  2.,  1.,  4.,  3.], [16., 17., 18., 19.,  1.,  2.,  3.,  4.], [20., 21., 22., 23.,  4.,  3.,  2.,  1.]]]))
  ```

- 对应元素计算

  ```python
  x = torch.tensor([1,2,4,8])
  y = torch.tensor([2,2,2,2])
  x+y, x-y, x*y, x/y, x**y, x==y, torch.exp(x)
  # (tensor([ 3,  4,  6, 10]),
  #  tensor([-1,  0,  2,  6]),
  #  tensor([ 2,  4,  8, 16]),
  #  tensor([0.5000, 1.0000, 2.0000, 4.0000]),
  #  tensor([ 1,  4, 16, 64]),
  #  tensor([False,  True, False, False]),
  #  tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03]))
  ```
  
- 广播机制

  ```python
  a = torch.arange(3).reshape((3,1)) # 当张量维度相同，结构不同，则广播机制会将元素复制为相同行列个数，进行运算
  b = torch.arange(2).reshape((1,2))
  a, b, a+b
  # (tensor([[0], [1], [2]]),
  #  tensor([[0, 1]]),
  #  tensor([[0, 1], [1, 2], [2, 3]]))
  ```

- 内存管理

  ```python
  X = torch.arange(12).reshape((3,4))
  Y = torch.arange(12).reshape((3,4))
  
  before = id(Y)	# 获取 Y 的地址
  Y[:] = Y + X	# 计算结果 Y + X 每个元素对应结果，赋值给对应元素，地址不变
  print(id(Y) == before)
  Y += X			# 将 X 直接加入 Y，地址不变
  print(id(Y) == before)
  Y = Y + X		# 将 X 于 Y 相加，重新赋值给 Y，地址变化
  print(id(Y) == before)
  # True True False
  ```

- 数据类型转换

  ```python
  A = X.numpy()
  B = torch.tensor(A)
  type(A), type(B)
  # (numpy.ndarray, torch.Tensor)
  
  a = torch.tensor([3.5])	# 大小为1的张量转换为 Python 标量
  a, a.item(), float(a), int(a)
  # (tensor([3.5000]), 3.5, 3.5, 3)
  ```

## 数据预处理

